import json
import os
import re
import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# âœ… WebDriver ì„¤ì •
options = Options()
# options.add_argument("--headless")  # ê°œë°œ ì¤‘ì—” ì£¼ì„ ì²˜ë¦¬
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option("useAutomationExtension", False)

driver = webdriver.Chrome(options=options)

# âœ… ì…€ë ˆë‹ˆì›€ ê°ì§€ ìš°íšŒ
driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
    "source": """
        Object.defineProperty(navigator, 'webdriver', {
            get: () => undefined
        })
    """
})

# âœ… ëŒ€ìƒ URL
url = "https://kream.co.kr/products/97779"
print(f"ğŸ”— ì ‘ì†í•  URL: {url}")
driver.get(url)

# âœ… ìš”ì†Œ ë¡œë”© ëŒ€ê¸°
try:
    WebDriverWait(driver, 15).until(
        EC.presence_of_element_located((By.CLASS_NAME, "product_title"))
    )
except:
    print("âŒ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨")

# âœ… HTML íŒŒì‹±
html = driver.page_source
soup = BeautifulSoup(html, "html.parser")

# âœ… ê²°ê³¼ ì €ì¥ dict
result = {"url": url}

# âœ… name & brand from <title>
title_tag = soup.find("title")
if title_tag:
    title_parts = title_tag.text.strip().split("|")
    if len(title_parts) >= 2:
        result["name"] = title_parts[0].strip()
        result["brand"] = title_parts[1].strip()

# âœ… model_number
model_number = soup.find(text=re.compile("ëª¨ë¸ë²ˆí˜¸"))
if model_number:
    sibling = model_number.find_parent().find_next("div")
    result["model_number"] = sibling.text.strip() if sibling else None

# âœ… release_price
release_price_tag = soup.find(text=re.compile("ë°œë§¤ê°€"))
if release_price_tag:
    sibling = release_price_tag.find_parent().find_next("div")
    if sibling:
        result["release_price"] = re.sub(r"[^\d]", "", sibling.text.strip())

# âœ… current_price
price_tag = soup.select_one(".price .amount")
result["current_price"] = re.sub(r"[^\d]", "", price_tag.text.strip()) if price_tag else None

# âœ… last_trade_price
last_price = soup.find(text=re.compile("ìµœê·¼ ê±°ë˜ê°€"))
if last_price:
    sibling = last_price.find_parent().find_next("div")
    result["last_trade_price"] = re.sub(r"[^\d]", "", sibling.text.strip()) if sibling else None

# âœ… color
color_tag = soup.find(text=re.compile("ëŒ€í‘œ ìƒ‰ìƒ"))
if color_tag:
    sibling = color_tag.find_parent().find_next("div")
    result["color"] = sibling.text.strip() if sibling else None

# âœ… description (ì—†ìœ¼ë©´ nameìœ¼ë¡œ ëŒ€ì²´)
desc = soup.select_one("div.detail_section .description")
result["description"] = desc.text.strip() if desc else result.get("name")

# âœ… delivery_info
delivery_tag = soup.find(text=re.compile("ë°°ì†¡ ì •ë³´"))
if delivery_tag:
    delivery_section = delivery_tag.find_parent("div")
    if delivery_section:
        result["delivery_info"] = delivery_section.get_text(strip=True)

# âœ… image_url
image = soup.select_one("picture img")
result["image_url"] = image["src"] if image else None

# âœ… review_score
score_tag = soup.find("div", class_=re.compile("score_area"))
if score_tag:
    score_text = score_tag.get_text()
    match = re.search(r"\d\.\d", score_text)
    if match:
        result["review_score"] = float(match.group())

# âœ… review_count
review_tag = soup.find(text=re.compile("ë¦¬ë·°"))
if review_tag:
    match = re.search(r"\d[\d,]*", review_tag)
    if match:
        result["review_count"] = int(match.group().replace(",", ""))

# âœ… ìˆ˜ì§‘ í•„ë“œ í™•ì¸
collected = [k for k, v in result.items() if v]
missing = [k for k, v in result.items() if not v]
print(f"ğŸŸ¢ ìˆ˜ì§‘ëœ í•„ë“œ: {collected}")
print(f"ğŸ”´ ëˆ„ë½ëœ í•„ë“œ: {missing}")

# âœ… JSON ì €ì¥
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
safe_name = result.get("name", "unknown").replace(" ", "_").replace("/", "_")
json_path = os.path.join(BASE_DIR, f"{safe_name}.json")
with open(json_path, "w", encoding="utf-8") as f:
    json.dump(result, f, ensure_ascii=False, indent=2)
print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {json_path}")

driver.quit()
