import json
import os
import re
import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# âœ… ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LINKS_PATH = os.path.join(BASE_DIR, "product_links.json")

# âœ… WebDriver ì„¤ì •
options = Options()
# options.add_argument("--headless")
options.add_argument("--disable-gpu")
options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option("useAutomationExtension", False)

driver = webdriver.Chrome(options=options)

# âœ… ì…€ë ˆë‹ˆì›€ ê°ì§€ ìš°íšŒ
driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
    "source": """
        Object.defineProperty(navigator, 'webdriver', {
            get: () => undefined
        })
    """
})

# âœ… product_links.json ë¶ˆëŸ¬ì˜¤ê¸°
with open(LINKS_PATH, "r", encoding="utf-8") as f:
    product_links = json.load(f)

# âœ… ê° URL í¬ë¡¤ë§
for idx, url in enumerate(product_links):
    print(f"\n[{idx+1}/{len(product_links)}] ğŸ”— ì ‘ì†í•  URL: {url}")
    try:
        driver.get(url)
        time.sleep(1)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "product_title"))
        )
        html = driver.page_source
        soup = BeautifulSoup(html, "html.parser")

        result = {"url": url}

        # âœ… name & brand from <title>
        title_tag = soup.find("title")
        if title_tag:
            parts = title_tag.text.strip().split("|")
            if len(parts) >= 2:
                result["name"] = parts[0].strip()
                result["brand"] = parts[1].strip()

        # âœ… model_number
        model_tag = soup.select_one("div.model_number span")
        result["model_number"] = model_tag.text.strip() if model_tag else None

        # âœ… release_price
        release_tag = soup.find(text=re.compile("ë°œë§¤ê°€"))
        if release_tag:
            price_text = release_tag.find_parent().find_next("div")
            if price_text:
                result["release_price"] = re.sub(r"[^\d]", "", price_text.text)

        # âœ… current_price
        curr_tag = soup.select_one(".price .amount")
        result["current_price"] = re.sub(r"[^\d]", "", curr_tag.text) if curr_tag else None

        # âœ… last_trade_price
        last_tag = soup.find(text=re.compile("ìµœê·¼ ê±°ë˜ê°€"))
        if last_tag:
            value = last_tag.find_parent().find_next("div")
            if value:
                result["last_trade_price"] = re.sub(r"[^\d]", "", value.text)

        # âœ… color
        color_tag = soup.find(text=re.compile("ëŒ€í‘œ ìƒ‰ìƒ"))
        if color_tag:
            value = color_tag.find_parent().find_next("div")
            if value:
                result["color"] = value.text.strip()

        # âœ… description
        desc_tag = soup.select_one("div.detail_section .description")
        result["description"] = desc_tag.text.strip() if desc_tag else result.get("name")

        # âœ… delivery_info
        delivery_tag = soup.find(text=re.compile("ë°°ì†¡ ì •ë³´"))
        if delivery_tag:
            section = delivery_tag.find_parent("div")
            result["delivery_info"] = section.get_text(strip=True) if section else None

        # âœ… image_url
        image_tag = soup.select_one("picture img")
        result["image_url"] = image_tag["src"] if image_tag else None

        # âœ… review_score
        score_tag = soup.find("div", class_=re.compile("score_area"))
        if score_tag:
            match = re.search(r"\d\.\d", score_tag.get_text())
            if match:
                result["review_score"] = float(match.group())

        # âœ… review_count
        review_tag = soup.find(text=re.compile("ë¦¬ë·°"))
        if review_tag:
            match = re.search(r"\d[\d,]*", review_tag)
            if match:
                result["review_count"] = int(match.group().replace(",", ""))

        # âœ… ìˆ˜ì§‘ í™•ì¸
        collected = [k for k, v in result.items() if v]
        missing = [k for k, v in result.items() if not v]
        print(f"ğŸŸ¢ ìˆ˜ì§‘ëœ í•„ë“œ: {collected}")
        print(f"ğŸ”´ ëˆ„ë½ëœ í•„ë“œ: {missing}")

        # âœ… JSON ì €ì¥
        safe_name = result.get("name", f"product_{idx+1}").replace(" ", "_").replace("/", "_")
        json_path = os.path.join(BASE_DIR, f"{safe_name}.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {json_path}")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

# âœ… ì¢…ë£Œ
driver.quit()
