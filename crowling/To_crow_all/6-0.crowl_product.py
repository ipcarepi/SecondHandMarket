import json
import time
import os
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# âœ… í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LINKS_PATH = os.path.join(BASE_DIR, "product_links.json")

# âœ… ì…€ë ˆë‹ˆì›€ ì˜µì…˜ ì„¤ì • (ìš°íšŒ í¬í•¨)
options = Options()
# options.add_argument("--headless")  # í•„ìš”ì‹œ ì£¼ì„ ì œê±°
options.add_argument("--disable-gpu")
options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)

driver = webdriver.Chrome(options=options)
driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
    "source": """
        Object.defineProperty(navigator, 'webdriver', {
            get: () => undefined
        })
    """
})

# âœ… URL ë¶ˆëŸ¬ì˜¤ê¸°
with open(LINKS_PATH, "r", encoding="utf-8") as f:
    product_links = json.load(f)

url = product_links[0]
print(f"ğŸ”— ì ‘ì†í•  URL: {url}")
driver.get(url)

try:
    WebDriverWait(driver, 15).until(
        EC.presence_of_element_located((By.CLASS_NAME, "product_title"))
    )
    time.sleep(2)
    html = driver.page_source
    soup = BeautifulSoup(html, "html.parser")

    # âœ… ë°ì´í„° ìˆ˜ì§‘
    result = {}
    result["url"] = url

    # ERD ê¸°ë°˜ í•­ëª©ë“¤
    result["name"] = soup.find("p", class_="product_title").text.strip() if soup.find("p", class_="product_title") else None
    result["brand"] = soup.find("p", class_="product_brand").text.strip() if soup.find("p", class_="product_brand") else None
    result["model_number"] = soup.select_one("div.model_number span").text.strip() if soup.select_one("div.model_number span") else None
    result["current_price"] = soup.select_one(".price .amount").text.replace(",", "").replace("ì›", "").strip() if soup.select_one(".price .amount") else None
    result["image_url"] = soup.select_one("picture img")["src"] if soup.select_one("picture img") else None
    result["description"] = soup.select_one("div.detail_section .description").text.strip() if soup.select_one("div.detail_section .description") else None

    # âœ… ê²°ê³¼ í™•ì¸
    collected = [k for k, v in result.items() if v]
    missing = [k for k, v in result.items() if not v]

    print("ğŸŸ¢ ìˆ˜ì§‘ëœ í•„ë“œ:", collected)
    print("ğŸ”´ ëˆ„ë½ëœ í•„ë“œ:", missing)

    # âœ… ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„± ë° ì €ì¥
    safe_name = result["name"] if result["name"] else "unknown"
    safe_name = re.sub(r"[\\/:*?\"<>|]", "_", safe_name.replace(" ", "_"))
    save_path = os.path.join(BASE_DIR, f"{safe_name}.json")

    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {save_path}")

except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

finally:
    driver.quit()
